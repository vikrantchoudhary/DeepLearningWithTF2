{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000 10000\n"
    }
   ],
   "source": [
    "# handwritten task with conv neural network\n",
    "# basically conv network is process to discard unwanted piece of pixel. work with compress pixel without damaging its utility\n",
    "# two parts with conv network \n",
    "# 1. filter matrix => which convert the existing matrix to horizontal and verical transformation \n",
    "# 2. pooling : take element from the matrix .. for example 64 element split to 4 , 4 * 4 matrix & take max from each matrix . then 64 elements reduced to 4 elements\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from os import path,getcwd,chdir\n",
    "\n",
    "#data \n",
    "path = f\"{getcwd()}/../data/mnist.npz\"\n",
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data(path = path)\n",
    "\n",
    "#normalize data \n",
    "(x_train,x_test) = (x_train/255.0,x_test/255.0)\n",
    "\n",
    "print(len(x_train),len(x_test))\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/5\n60000/60000 [==============================] - 6s 105us/sample - loss: 0.2040 - accuracy: 0.9400\nEpoch 2/5\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0811 - accuracy: 0.9752\nEpoch 3/5\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0522 - accuracy: 0.9837\nEpoch 4/5\n60000/60000 [==============================] - 6s 99us/sample - loss: 0.0372 - accuracy: 0.9885\nEpoch 5/5\n60000/60000 [==============================] - 6s 102us/sample - loss: 0.0267 - accuracy: 0.9919\n[0, 1, 2, 3, 4] 0.9919\n"
    }
   ],
   "source": [
    "#Abstract Neural network \n",
    "# result may be better than cnn for small data sets but in long run it will be a issue\n",
    "\n",
    "model =tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "history =  model.fit(x_train,y_train,epochs=5)\n",
    "\n",
    "print(history.epoch, history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_14 (Conv2D)           (None, 26, 26, 64)        640       \n_________________________________________________________________\nmax_pooling2d_14 (MaxPooling (None, 13, 13, 64)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 11, 11, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten_10 (Flatten)         (None, 1600)              0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 512)               819712    \n_________________________________________________________________\ndense_21 (Dense)             (None, 10)                5130      \n=================================================================\nTotal params: 862,410\nTrainable params: 862,410\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 60000 samples\nEpoch 1/5\n60000/60000 [==============================] - 52s 875us/sample - loss: 0.1048 - accuracy: 0.9675\nEpoch 2/5\n60000/60000 [==============================] - 51s 857us/sample - loss: 0.0360 - accuracy: 0.9889\nEpoch 3/5\n60000/60000 [==============================] - 52s 863us/sample - loss: 0.0247 - accuracy: 0.9923\nEpoch 4/5\n60000/60000 [==============================] - 52s 862us/sample - loss: 0.0175 - accuracy: 0.9944\nEpoch 5/5\n60000/60000 [==============================] - 80s 1ms/sample - loss: 0.0115 - accuracy: 0.9963\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1525cf090>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "(x_train,x_test) = (x_train.reshape(60000,28,28,1),x_test.reshape(10000,28,28,1))\n",
    "model =tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu,input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train,y_train,epochs=5)\n",
    "\n",
    "#print(history.epoch, history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 2s 226us/sample - loss: 0.0377 - accuracy: 0.9890\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.037729105553491175, 0.989]"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}