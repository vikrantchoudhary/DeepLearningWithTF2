{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handwritten task with conv neural network\n",
    "# basically conv network is process to discard unwanted piece of pixel. work with compress pixel without damaging its utility\n",
    "# two parts with conv network \n",
    "# 1. filter matrix => which convert the existing matrix to horizontal and verical transformation \n",
    "# 2. pooling : take element from the matrix .. for example 64 element split to 4 , 4 * 4 matrix & take max from each matrix . then 64 elements reduced to 4 elements\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from os import path,getcwd,chdir\n",
    "\n",
    "#data \n",
    "path = f\"{getcwd()}/../data/mnist.npz\"\n",
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data(path = path)\n",
    "\n",
    "#normalize data \n",
    "(x_train,x_test) = (x_train/255.0,x_test/255.0)\n",
    "\n",
    "model =tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "history =  model.fit(x_train,y_train,epochs=5)\n",
    "\n",
    "print(history.epoch, history.history['acc'][-1])\n",
    "\n"
   ]
  }
 ]
}