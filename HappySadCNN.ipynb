{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['happy1-19.png', 'happy1-18.png', 'happy1-08.png', 'happy1-09.png', 'happy2-17.png', 'happy2-03.png', 'happy2-02.png', 'happy2-16.png', 'happy2-00.png', 'happy2-14.png']\n['sad1-09.png', 'sad1-08.png', 'sad1-18.png', 'sad1-19.png', 'sad2-10.png', 'sad2-04.png', 'sad2-05.png', 'sad2-11.png', 'sad2-07.png', 'sad2-13.png']\n"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "\n",
    "#data downloaded from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n",
    "happy_datadir = os.path.join('../data/happy-or-sad/happy')\n",
    "sad_datadir = os.path.join('../data/happy-or-sad/sad')\n",
    "\n",
    "happy_names = os.listdir(happy_datadir)\n",
    "sad_names = os.listdir(sad_datadir)\n",
    "\n",
    "print (happy_names[:10])\n",
    "print(sad_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Happy data = 40 , Sad data = 40 \n"
    }
   ],
   "source": [
    "# total images\n",
    "print (\"Happy data = {0} , Sad data = {1} \" .format(len(happy_names),len(sad_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "         # Your Code\n",
    "         def on_epoch_end(self,epoch,logs={}):\n",
    "             if (logs.get('acc') >0.999):\n",
    "                 self.model.stop_training = True \n",
    "    \n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Your Code Here\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation=tf.nn.relu, input_shape=(150,150,3) ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
    "\n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(learning_rate=0.001),metrics=['acc'])\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "         '../data/happy-or-sad/',\n",
    "        target_size = (150,150),\n",
    "        batch_size = 128,\n",
    "        class_mode = 'binary'\n",
    "    )\n",
    "        # Your Code Here)\n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=2,epochs=15,verbose=1)\n",
    "          # Your Code Here)\n",
    "    # model fitting\n",
    "    return history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 80 images belonging to 2 classes.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 2 steps\nEpoch 1/15\n1/2 [==============>...............] - ETA: 1s - loss: 0.6945 - acc: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train_happy_sad_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}